{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3d474ff-9c02-48e6-a341-d7f24e36c256",
   "metadata": {},
   "source": [
    "This notebook demonstrates use of the TorchRF DataLogger.  See LogDemoA for an overview and examples of writing out reference values.  In this notebook we load in those saved values and compare them to values created here. \n",
    "\n",
    "# Part 2: Compute test values and compare them with the reference values\n",
    "We start with setting up the scene in TorchRF the same way we did for Sionna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd116cd-2506-41f3-abd2-a9a156e6a663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 21:51:21.636059: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchrf\n",
    "from torchrf.rt.scene import load_scene\n",
    "from torchrf.rt import PlanarArray, Transmitter, Camera\n",
    "\n",
    "scene = load_scene(torchrf.rt.scene.munich)\n",
    "resolution = [480, 320]\n",
    "my_cam = Camera(\"my_cam\", position=[-250, 250, 150], look_at=[-15, 30, 28])\n",
    "scene.add(my_cam)\n",
    "scene.tx_array = PlanarArray(num_rows=1, num_cols=1, vertical_spacing=0.5, horizontal_spacing=0.5,\n",
    "                             pattern=\"tr38901\",polarization=\"V\")\n",
    "tx = Transmitter(name=\"tx\", position=[8.5, 21, 27])\n",
    "scene.add(tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03cb9c6-c01e-41d1-8783-864227222b2b",
   "metadata": {},
   "source": [
    "Import the DataLogger. The default mode is 'break', which calls a breakpoint so that you can use the debugger to inspect the differences between the current code and the reference computation.  Since we're in a Jupyter Notebook right now, we will use mode 'print' instead which just prints out disagreements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cbd7890-2bc5-4b91-9e10-3f1cfbe77313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchrf.utils.datalogger.DataLogger at 0x108496ce0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchrf.utils.datalogger import DataLogger\n",
    "DataLogger().set_mode('print')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc5c8c2-d93e-4fee-bd54-c8af285494f1",
   "metadata": {},
   "source": [
    "The simplest way to compare a variable to reference is just to call compare. You'll need to use the identical tag in order to compare to the correct variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2261751-1933-4d53-b8c7-b25f98580e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At log point `transmitter1`:\n",
      "  stored data object [data] has keys not in current data object [obj]:\n",
      "   _color\n",
      "  current data object [obj] has keys not in stored data object [data]:\n",
      "   _trainable_position\n",
      "   _trainable_orientationn\n",
      "At log point `transmitter1:[_dtype]`:\n",
      "  torch.complex64 does not match {'__doc__': '64-bit complex.'}\n",
      "At log point `transmitter1:[_rdtype]`:\n",
      "  torch.float32 does not match {'__doc__': '32-bit (single precision) floating-point.'}\n"
     ]
    }
   ],
   "source": [
    "logger = DataLogger()\n",
    "logger.compare(tx, 'transmitter1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfca171-291e-4ad6-bc14-e9c60611da32",
   "metadata": {},
   "source": [
    "Because the comparison was successful, we get a message that this tag \"passed\".  Note that this tx contains torch tensors while the reference tx contained tensorflow tensors, but both were converted to numpy ndarrays, so the comparison went through.  The comparison done on the Transmitter class was \"deep\", in that all fields (and fields of fields, etc) other than the Scene were compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8498f5d3-7691-42d4-8c33-8d8102ba352f",
   "metadata": {},
   "source": [
    "Recall that in LogDemoA, the 753array contained a set of 3 vectors: {(3,3,3), (5,5,5), (7,7,7)} with the vectors stored in dim=1, but specfically they were stored with the 7's leftmost and the 3's rightmost.  Let's try a shuffle of those vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15d2d6ab-25eb-430c-8995-5333cd8eec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At log point `753array`:\n",
      "   tensors have different values\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[5, 3, 7],\n",
    "              [5, 3, 7],\n",
    "              [5, 3, 7]])\n",
    "logger.compare(a, '753array')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a6cf64-f234-4198-a6a4-2df45ef92452",
   "metadata": {},
   "source": [
    "As expected, that comparison fails because the tensors are not equivalent.  But if we know that we only want to know \n",
    "whether these are the same set of unique vectors, we can use the `unique` keyword.  In this case we will also need to \n",
    "specify the dim (it's the same one used as an argument to the tf or torch `unique` functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b69325d-a012-46ae-b75f-5af9fe77e118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At log point `753array`: passed\n"
     ]
    }
   ],
   "source": [
    "logger.compare(a, '753array', unique=True, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89376df-e355-473e-8856-e560b6659431",
   "metadata": {},
   "source": [
    "This only works if the vectors really were unique, so the following fails, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5efeab51-ebeb-4c4a-bbdd-e59fe22f727a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At log point `753array`:\n",
      "   tensors have different shapes\n"
     ]
    }
   ],
   "source": [
    "logger.compare(np.array([[5, 7, 3, 7],\n",
    "                         [5, 7, 3, 7],\n",
    "                         [5, 7, 3, 7]]), '753array', unique=True, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e5e1f2-36c8-4f07-9d17-38f97ab7b750",
   "metadata": {},
   "source": [
    "We build up tag stacks for reading and comparing in the same way as when writing.  The data will only be compared when the entire stack matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae7fa24a-3e35-4801-81fc-5ea8e7fc91f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At log point `foo A:intermediate foo`: passed\n",
      "At log point `foo A:first returned z`: passed\n",
      "At log point `foo A:foo 2:intermediate foo`: passed\n",
      "At log point `foo A:foo 2:foo 3:intermediate foo`: passed\n"
     ]
    }
   ],
   "source": [
    "def foo(x):\n",
    "    y = x * x\n",
    "    logger.compare(y, 'intermediate foo')\n",
    "    z = y / 2\n",
    "    return z\n",
    "\n",
    "with DataLogger().push('foo A') as logger:\n",
    "    z1 = foo(7)\n",
    "    logger.compare(z1, 'first returned z')\n",
    "    with logger.push('foo 2') as logger:\n",
    "        z2 = foo(5)\n",
    "        with logger.push('foo 3') as logger:\n",
    "            z3 = foo(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdf7674-c7af-43e6-b750-3612eb3d578b",
   "metadata": {},
   "source": [
    "Recall that LogDemoA wrote a random matrix.  We will obviously fail on that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dadb2f76-3707-4332-b9cc-1acd50f0b7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At log point `rand:A`:\n",
      "   tensors have different values\n"
     ]
    }
   ],
   "source": [
    "with DataLogger().push('rand') as logger:\n",
    "    a = np.random.rand(3, 5)\n",
    "    logger.compare(a, 'A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03da799d-7430-4ffc-b41f-f959056d8abc",
   "metadata": {},
   "source": [
    "But we might want to make sure that our function `foo` operates on that random matrix the same way that the original `foo`.  We can do that by explicitly loading in the saved data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55d90a2b-40ed-4a59-82db-59f8d7f4548f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At log point `rand:intermediate foo`: passed\n",
      "At log point `rand:foo A`: passed\n"
     ]
    }
   ],
   "source": [
    "with DataLogger().push('rand') as logger:\n",
    "    a = logger.get('A')\n",
    "    z = foo(a)\n",
    "    logger.compare(z, 'foo A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48aeec4-b8ae-4d5b-9d73-935a3701b660",
   "metadata": {},
   "source": [
    "# Part 3: Other Details\n",
    "\n",
    "It was mentioned above that `logs` and `logs/index.json` are the default storage places.  These can be overridden using `DataLogger().set_dir(log_directory)` and `DataLogger().set_index(index_file_spec)`.  These can be absolute or relative file paths.\n",
    "\n",
    "`pickle` only pickles certain data types.  `DataLogger.prepickle()` converts data objects into pickleable objects.  It covers the cases that have come up so far, but might not cover everything we want to pickle and so may need to be extended.\n",
    "\n",
    "As described above, the DataLogger tool requires us to add code to the actual source that we want to test, so it isn't really used like unit test code unless we only want to compare input and output values without intermediate values.  Because the Sionna methods contain long internal computations, we will want the intermediate values, requiring us to put DataLogger calls into the Sionna source code as well as the TorchRF code.  Some of the work to be done is to try to guess how the different variables align, and this gives us a way to check our guesses.  After we have finished debugging, we will presumably want to go through and eliminate DataLogger calls before making code public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e7a40b-295d-42b2-aa5d-de0656c22f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
